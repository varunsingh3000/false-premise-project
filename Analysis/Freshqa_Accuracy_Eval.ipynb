{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce30760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baae8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv_path = \"../fpdar/freshqa/gpt-3.5-turbo_fpdar.csv\"\n",
    "\n",
    "df = pd.read_csv(result_csv_path)\n",
    "\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39b71574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of instances in each category\n",
    "total_no = 500\n",
    "total_fp = 124\n",
    "total_tp = 376\n",
    "total_fp_before22 = 91\n",
    "total_tp_fast = 127\n",
    "total_tp_slow = 125\n",
    "total_tp_never = 124\n",
    "total_tp_before22 = 140\n",
    "total_tp_after2022 = 236\n",
    "total_tp_single_hop = 280\n",
    "total_tp_multi_hop = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01ed86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total accuracy\n",
    "total_accuracy = df[df['final_accuracy'] == 'Correct'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ff1cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where false_premise is True i.e there is a false premise\n",
    "fp_filtered_df = df[df['premise']]\n",
    "\n",
    "# Calculate accuracy when false_premise is True\n",
    "accuracy_fp = fp_filtered_df[fp_filtered_df['final_accuracy'] == 'Correct'].shape[0]\n",
    "\n",
    "# Calculate accuracy when false_premise is False and the effective years\n",
    "accuracy_fp_year_before22 = fp_filtered_df[(fp_filtered_df['final_accuracy'] == 'Correct') & \n",
    "                            (fp_filtered_df['effective_year'] == \"before 2022\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8327f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where false_premise is False i.e there is a true premise\n",
    "tp_filtered_df = df[~df['premise']]\n",
    "\n",
    "# Calculate accuracy when false_premise is False\n",
    "accuracy_tp = tp_filtered_df[tp_filtered_df['final_accuracy'] == \n",
    "                             'Correct'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf9612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy when false_premise is False and the various fact type\n",
    "accuracy_tp_fact_fast = tp_filtered_df[(tp_filtered_df['final_accuracy'] == \n",
    "    'Correct') & (tp_filtered_df['fact_type'] == \"fast-changing\")].shape[0]\n",
    "\n",
    "accuracy_tp_fact_slow = tp_filtered_df[(tp_filtered_df['final_accuracy'] == \n",
    "    'Correct') & (tp_filtered_df['fact_type'] == \"slow-changing\")].shape[0]\n",
    "\n",
    "accuracy_tp_fact_never = tp_filtered_df[(tp_filtered_df['final_accuracy'] == \n",
    "    'Correct') & (tp_filtered_df['fact_type'] == \"never-changing\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc9fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy when false_premise is False and the effective years\n",
    "accuracy_tp_year_before22 = tp_filtered_df[(tp_filtered_df['final_accuracy'] == \n",
    "   'Correct') & (tp_filtered_df['effective_year'] == \"before 2022\")].shape[0]\n",
    "\n",
    "accuracy_tp_year_after22 = tp_filtered_df[(tp_filtered_df['final_accuracy'] == \n",
    "    'Correct') & (tp_filtered_df['effective_year'] != \"before 2022\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8152f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy when false_premise is False and the question hops\n",
    "accuracy_tp_single_hop = tp_filtered_df[(tp_filtered_df['final_accuracy'] == \n",
    "        'Correct') & (tp_filtered_df['num_hops'] == \"one-hop\")].shape[0]\n",
    "\n",
    "accuracy_tp_multi_hop = tp_filtered_df[(tp_filtered_df['final_accuracy'] == \n",
    "        'Correct') & (tp_filtered_df['num_hops'] == \"multi-hop\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffa213be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct: 320, FP Correct: 68, TP Correct: 252\n"
     ]
    }
   ],
   "source": [
    "# print raw results for overall, fp and tp accuracy\n",
    "\n",
    "print(\"Total Correct: {}, FP Correct: {}, TP Correct: {}\".format(total_accuracy,accuracy_fp,accuracy_tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8c35b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct: 320\n",
      "FP Correct: 68\n",
      "FP Before 2022: 57\n",
      "TP Correct:       252\n",
      "TP Fast: 51\n",
      "TP Slow: 85\n",
      "TP Never: 116\n",
      "TP Before 2022: 124\n",
      "TP After       2022: 128\n",
      "TP Single Hop: 201\n",
      "TP Multi Hop: 51\n"
     ]
    }
   ],
   "source": [
    "# print raw results for fine grain evaluation\n",
    "\n",
    "print(\"Total Correct: {}\\nFP Correct: {}\\nFP Before 2022: {}\\nTP Correct: \\\n",
    "      {}\\nTP Fast: {}\\nTP Slow: {}\\nTP Never: {}\\nTP Before 2022: {}\\nTP After \\\n",
    "      2022: {}\\nTP Single Hop: {}\\nTP Multi Hop: {}\".format( \n",
    "    total_accuracy, accuracy_fp, accuracy_fp_year_before22, accuracy_tp,\n",
    "    accuracy_tp_fact_fast, accuracy_tp_fact_slow, accuracy_tp_fact_never,\n",
    "    accuracy_tp_year_before22, accuracy_tp_year_after22,\n",
    "    accuracy_tp_single_hop, accuracy_tp_multi_hop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42c397ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy values as percentage\n",
    "total_accuracy_pr = round(total_accuracy / total_no * 100, 1)\n",
    "accuracy_fp_pr = round(accuracy_fp / total_fp * 100, 1)\n",
    "accuracy_fp_year_before22_pr = round(accuracy_fp_year_before22 / total_fp_before22 * 100, 1)\n",
    "accuracy_tp_pr = round(accuracy_tp / total_tp * 100, 1)\n",
    "accuracy_tp_fact_fast_pr = round(accuracy_tp_fact_fast / total_tp_fast * 100, 1)\n",
    "accuracy_tp_fact_slow_pr = round(accuracy_tp_fact_slow / total_tp_slow * 100, 1)\n",
    "accuracy_tp_fact_never_pr = round(accuracy_tp_fact_never / total_tp_never * 100, 1)\n",
    "accuracy_tp_year_before22_pr = round(accuracy_tp_year_before22 / total_tp_before22 * 100, 1)\n",
    "accuracy_tp_year_after22_pr = round(accuracy_tp_year_after22 / total_tp_after2022 * 100, 1)\n",
    "accuracy_tp_single_hop_pr = round(accuracy_tp_single_hop / total_tp_single_hop * 100, 1)\n",
    "accuracy_tp_multi_hop_pr = round(accuracy_tp_multi_hop / total_tp_multi_hop * 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cc31c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy (%): 64.0\n",
      "FP Accuracy (%): 54.8\n",
      "FP Before 2022 Accuracy (%): 62.6\n",
      "TP Accuracy (%): 67.0\n",
      "TP Fast Fact Accuracy (%): 40.2\n",
      "TP Slow Fact Accuracy (%): 68.0\n",
      "TP Never Fact Accuracy (%): 93.5\n",
      "TP Before 2022 Accuracy (%): 88.6\n",
      "TP After 2022 Accuracy (%): 54.2\n",
      "TP Single Hop Accuracy (%): 71.8\n",
      "TP Multi Hop Accuracy (%): 53.1\n"
     ]
    }
   ],
   "source": [
    "# Print the rounded values\n",
    "print(\"Total Accuracy (%):\", total_accuracy_pr)\n",
    "print(\"FP Accuracy (%):\", accuracy_fp_pr)\n",
    "print(\"FP Before 2022 Accuracy (%):\", accuracy_fp_year_before22_pr)\n",
    "print(\"TP Accuracy (%):\", accuracy_tp_pr)\n",
    "print(\"TP Fast Fact Accuracy (%):\", accuracy_tp_fact_fast_pr)\n",
    "print(\"TP Slow Fact Accuracy (%):\", accuracy_tp_fact_slow_pr)\n",
    "print(\"TP Never Fact Accuracy (%):\", accuracy_tp_fact_never_pr)\n",
    "print(\"TP Before 2022 Accuracy (%):\", accuracy_tp_year_before22_pr)\n",
    "print(\"TP After 2022 Accuracy (%):\", accuracy_tp_year_after22_pr)\n",
    "print(\"TP Single Hop Accuracy (%):\", accuracy_tp_single_hop_pr)\n",
    "print(\"TP Multi Hop Accuracy (%):\", accuracy_tp_multi_hop_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994448f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
